{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Sentinel-1 GRD Data with EOPFZARR Driver\n",
    "\n",
    "This notebook demonstrates accessing Sentinel-1 Ground Range Detected (GRD) SAR data using the EOPFZARR GDAL driver.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Product Type**: S01SEWGRD (Sentinel-1C Extra Wide mode Ground Range Detected)\n",
    "- **Dataset**: S1C_EW_GRDM_1SSH from EODC\n",
    "- **Key Features**: SAR amplitude data with Ground Control Points (GCPs)\n",
    "\n",
    "## Sentinel-1 GRD Structure\n",
    "\n",
    "Unlike optical sensors (Sentinel-2/3), Sentinel-1 uses:\n",
    "- **Sparse GCP grid** instead of dense lat/lon arrays\n",
    "- **Ground Control Points** at `conditions/gcp/latitude` and `conditions/gcp/longitude`\n",
    "- **Measurement data** at `measurements/grd` (SAR backscatter amplitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# Enable GDAL exceptions\n",
    "gdal.UseExceptions()\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")\n",
    "print(f\"GDAL version: {gdal.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset_url",
   "metadata": {},
   "source": [
    "## 2. Dataset Configuration\n",
    "\n",
    "We'll use a Sentinel-1C Extra Wide mode GRD product from EODC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentinel-1 GRD dataset URL\n",
    "base_url = (\n",
    "    \"https://objects.eodc.eu/e05ab01a9d56408d82ac32d69a5aae2a:202601-s01sewgrm-global/\"\n",
    "    \"29/products/cpm_v262/S1C_EW_GRDM_1SSH_20260129T124421_20260129T124526_\"\n",
    "    \"006118_00C473_F440.zarr\"\n",
    ")\n",
    "\n",
    "# Construct EOPFZARR path\n",
    "zarr_path = f'EOPFZARR:\"/vsicurl/{base_url}\"'\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Platform: Sentinel-1C\")\n",
    "print(f\"Product Type: S1C_EW_GRDM_1SSH (Extra Wide Ground Range Medium Resolution)\")\n",
    "print(f\"Acquisition: 2026-01-29 12:44:21 to 12:45:26 UTC\")\n",
    "print(f\"Polarization: HH\")\n",
    "print(f\"\\nZarr path: {zarr_path}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "open_root",
   "metadata": {},
   "source": [
    "## 3. Open Root Dataset and List Subdatasets\n",
    "\n",
    "First, let's open the root dataset to discover all available subdatasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list_subdatasets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open root dataset\n",
    "print(\"Opening root dataset...\\n\")\n",
    "root_ds = gdal.Open(zarr_path)\n",
    "\n",
    "if root_ds is None:\n",
    "    print(\"‚ùå Failed to open dataset!\")\n",
    "else:\n",
    "    print(\"‚úÖ Root dataset opened successfully\\n\")\n",
    "    \n",
    "    # Get subdatasets\n",
    "    subdatasets = root_ds.GetMetadata(\"SUBDATASETS\")\n",
    "    \n",
    "    # Parse subdataset list\n",
    "    sub_list = []\n",
    "    i = 1\n",
    "    while f\"SUBDATASET_{i}_NAME\" in subdatasets:\n",
    "        name = subdatasets[f\"SUBDATASET_{i}_NAME\"]\n",
    "        desc = subdatasets.get(f\"SUBDATASET_{i}_DESC\", \"\")\n",
    "        sub_list.append((name, desc))\n",
    "        i += 1\n",
    "    \n",
    "    print(f\"Total subdatasets: {len(sub_list)}\\n\")\n",
    "    \n",
    "    # Categorize subdatasets\n",
    "    measurements = []\n",
    "    gcp_arrays = []\n",
    "    other = []\n",
    "    \n",
    "    for name, desc in sub_list:\n",
    "        # Extract path from EOPFZARR format\n",
    "        if '\":/' in name:\n",
    "            path = name.split('\":/')[1]\n",
    "        else:\n",
    "            path = name\n",
    "        \n",
    "        if 'measurements' in path:\n",
    "            measurements.append((path, name))\n",
    "        elif 'conditions/gcp' in path:\n",
    "            gcp_arrays.append((path, name))\n",
    "        else:\n",
    "            other.append((path, name))\n",
    "    \n",
    "    print(\"üìä Measurement Arrays:\")\n",
    "    print(\"=\" * 80)\n",
    "    for path, _ in measurements:\n",
    "        print(f\"  {path}\")\n",
    "    \n",
    "    print(\"\\nüåç Ground Control Point (GCP) Arrays:\")\n",
    "    print(\"=\" * 80)\n",
    "    for path, _ in gcp_arrays:\n",
    "        print(f\"  {path}\")\n",
    "    \n",
    "    print(f\"\\nüìã Other Arrays: {len(other)}\")\n",
    "    if len(other) <= 10:\n",
    "        for path, _ in other:\n",
    "            print(f\"  {path}\")\n",
    "    else:\n",
    "        for path, _ in other[:10]:\n",
    "            print(f\"  {path}\")\n",
    "        print(f\"  ... and {len(other) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspect_metadata",
   "metadata": {},
   "source": [
    "## 4. Inspect Root Dataset Metadata\n",
    "\n",
    "Check what geospatial metadata is available at the root level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "root_metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Root Dataset Metadata:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Driver: {root_ds.GetDriver().ShortName}\")\n",
    "print(f\"Size: {root_ds.RasterXSize} x {root_ds.RasterYSize}\")\n",
    "print(f\"Bands: {root_ds.RasterCount}\")\n",
    "\n",
    "# Check for CRS\n",
    "srs = root_ds.GetProjection()\n",
    "if srs:\n",
    "    print(f\"\\nProjection: {srs[:100]}...\")\n",
    "else:\n",
    "    print(\"\\nProjection: None\")\n",
    "\n",
    "# Check for GeoTransform\n",
    "gt = root_ds.GetGeoTransform()\n",
    "if gt and gt != (0, 1, 0, 0, 0, 1):\n",
    "    print(f\"\\nGeoTransform: {gt}\")\n",
    "    print(f\"  Origin: ({gt[0]:.4f}, {gt[3]:.4f})\")\n",
    "    print(f\"  Pixel Size: ({gt[1]:.6f}, {gt[5]:.6f})\")\n",
    "else:\n",
    "    print(\"\\nGeoTransform: Default (no georeferencing)\")\n",
    "\n",
    "# Check for metadata domains\n",
    "domains = root_ds.GetMetadataDomainList()\n",
    "print(f\"\\nMetadata Domains: {domains}\")\n",
    "\n",
    "# Check for GEOLOCATION metadata\n",
    "if 'GEOLOCATION' in (domains or []):\n",
    "    geoloc_md = root_ds.GetMetadata('GEOLOCATION')\n",
    "    print(\"\\nüåç GEOLOCATION Metadata:\")\n",
    "    for key, value in geoloc_md.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No GEOLOCATION metadata found at root level\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "open_grd",
   "metadata": {},
   "source": [
    "## 5. Open GRD Measurement Data\n",
    "\n",
    "Now let's open the main SAR amplitude data (GRD = Ground Range Detected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "open_measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the GRD measurement array\n",
    "grd_path = None\n",
    "for path, full_name in measurements:\n",
    "    if path.endswith('/grd'):\n",
    "        grd_path = full_name\n",
    "        break\n",
    "\n",
    "if grd_path is None:\n",
    "    print(\"‚ùå GRD measurement array not found!\")\n",
    "else:\n",
    "    print(f\"Opening: {grd_path.split('\":/')[1]}\\n\")\n",
    "    \n",
    "    grd_ds = gdal.Open(grd_path)\n",
    "    \n",
    "    if grd_ds is None:\n",
    "        print(\"‚ùå Failed to open GRD dataset!\")\n",
    "    else:\n",
    "        print(\"‚úÖ GRD dataset opened successfully\\n\")\n",
    "        \n",
    "        print(\"GRD Measurement Metadata:\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Driver: {grd_ds.GetDriver().ShortName}\")\n",
    "        print(f\"Dimensions: {grd_ds.RasterXSize} x {grd_ds.RasterYSize} pixels\")\n",
    "        print(f\"Bands: {grd_ds.RasterCount}\")\n",
    "        \n",
    "        # Band information\n",
    "        band = grd_ds.GetRasterBand(1)\n",
    "        print(f\"\\nBand 1:\")\n",
    "        print(f\"  Data Type: {gdal.GetDataTypeName(band.DataType)}\")\n",
    "        print(f\"  Block Size: {band.GetBlockSize()}\")\n",
    "        print(f\"  NoData Value: {band.GetNoDataValue()}\")\n",
    "        \n",
    "        # Check for CRS\n",
    "        srs = grd_ds.GetProjection()\n",
    "        if srs:\n",
    "            print(f\"\\nProjection: {srs[:80]}...\")\n",
    "        else:\n",
    "            print(\"\\nProjection: None\")\n",
    "        \n",
    "        # Check for GeoTransform\n",
    "        gt = grd_ds.GetGeoTransform()\n",
    "        if gt and gt != (0, 1, 0, 0, 0, 1):\n",
    "            print(f\"\\nGeoTransform: {gt}\")\n",
    "            print(f\"  Origin: ({gt[0]:.4f}, {gt[3]:.4f})\")\n",
    "            print(f\"  Pixel Size: ({gt[1]:.6f}, {gt[5]:.6f})\")\n",
    "        else:\n",
    "            print(\"\\nGeoTransform: Default (no georeferencing)\")\n",
    "        \n",
    "        # Check for GEOLOCATION metadata\n",
    "        domains = grd_ds.GetMetadataDomainList()\n",
    "        if 'GEOLOCATION' in (domains or []):\n",
    "            geoloc_md = grd_ds.GetMetadata('GEOLOCATION')\n",
    "            print(\"\\nüåç GEOLOCATION Metadata:\")\n",
    "            for key, value in geoloc_md.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è  No GEOLOCATION metadata found\")\n",
    "        \n",
    "        # Check for GCPs\n",
    "        gcp_count = grd_ds.GetGCPCount()\n",
    "        if gcp_count > 0:\n",
    "            print(f\"\\nüéØ Ground Control Points: {gcp_count}\")\n",
    "            gcps = grd_ds.GetGCPs()\n",
    "            print(f\"\\nFirst 5 GCPs:\")\n",
    "            for i, gcp in enumerate(gcps[:5]):\n",
    "                print(f\"  GCP {i+1}: Pixel({gcp.GCPPixel:.1f}, {gcp.GCPLine:.1f}) -> \"\n",
    "                      f\"Geo({gcp.GCPX:.4f}, {gcp.GCPY:.4f})\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è  No GCPs found (count: {gcp_count})\")\n",
    "        \n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspect_gcp",
   "metadata": {},
   "source": [
    "## 6. Inspect GCP Arrays Directly\n",
    "\n",
    "Let's open and examine the GCP latitude/longitude arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "read_gcp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find GCP arrays\n",
    "gcp_lat_path = None\n",
    "gcp_lon_path = None\n",
    "\n",
    "for path, full_name in gcp_arrays:\n",
    "    if 'latitude' in path:\n",
    "        gcp_lat_path = full_name\n",
    "    elif 'longitude' in path:\n",
    "        gcp_lon_path = full_name\n",
    "\n",
    "if gcp_lat_path and gcp_lon_path:\n",
    "    print(\"Opening GCP arrays...\\n\")\n",
    "    \n",
    "    # Open latitude\n",
    "    lat_ds = gdal.Open(gcp_lat_path)\n",
    "    print(f\"‚úÖ Latitude: {gcp_lat_path.split('\":/')[1]}\")\n",
    "    print(f\"   Dimensions: {lat_ds.RasterXSize} x {lat_ds.RasterYSize}\")\n",
    "    lat_array = lat_ds.ReadAsArray()\n",
    "    print(f\"   Shape: {lat_array.shape}\")\n",
    "    print(f\"   Range: [{lat_array.min():.4f}, {lat_array.max():.4f}]¬∞\")\n",
    "    \n",
    "    # Open longitude\n",
    "    lon_ds = gdal.Open(gcp_lon_path)\n",
    "    print(f\"\\n‚úÖ Longitude: {gcp_lon_path.split('\":/')[1]}\")\n",
    "    print(f\"   Dimensions: {lon_ds.RasterXSize} x {lon_ds.RasterYSize}\")\n",
    "    lon_array = lon_ds.ReadAsArray()\n",
    "    print(f\"   Shape: {lon_array.shape}\")\n",
    "    print(f\"   Range: [{lon_array.min():.4f}, {lon_array.max():.4f}]¬∞\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"GCP Grid Structure:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"GRD Data: {grd_ds.RasterXSize} x {grd_ds.RasterYSize} pixels (full resolution)\")\n",
    "    print(f\"GCP Grid: {lat_array.shape[1]} x {lat_array.shape[0]} points (sparse grid)\")\n",
    "    print(f\"\\nSampling Ratio:\")\n",
    "    print(f\"  X: 1 GCP every ~{grd_ds.RasterXSize / lat_array.shape[1]:.0f} pixels\")\n",
    "    print(f\"  Y: 1 GCP every ~{grd_ds.RasterYSize / lat_array.shape[0]:.0f} pixels\")\n",
    "    print(\"\\n‚ö†Ô∏è  This is a SPARSE geolocation grid, not dense per-pixel coordinates\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"‚ùå GCP latitude/longitude arrays not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize_gcp",
   "metadata": {},
   "source": [
    "## 7. Visualize GCP Grid\n",
    "\n",
    "Let's visualize the sparse GCP grid to understand its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_gcp_grid",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gcp_lat_path and gcp_lon_path:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    \n",
    "    # Plot 1: Latitude grid\n",
    "    im1 = axes[0].imshow(lat_array, cmap='coolwarm', aspect='auto')\n",
    "    axes[0].set_title('GCP Latitude Grid\\n(Sparse Control Points)', fontweight='bold')\n",
    "    axes[0].set_xlabel('GCP X Index')\n",
    "    axes[0].set_ylabel('GCP Y Index')\n",
    "    plt.colorbar(im1, ax=axes[0], label='Latitude (¬∞)')\n",
    "    \n",
    "    # Plot 2: Longitude grid\n",
    "    im2 = axes[1].imshow(lon_array, cmap='coolwarm', aspect='auto')\n",
    "    axes[1].set_title('GCP Longitude Grid\\n(Sparse Control Points)', fontweight='bold')\n",
    "    axes[1].set_xlabel('GCP X Index')\n",
    "    axes[1].set_ylabel('GCP Y Index')\n",
    "    plt.colorbar(im2, ax=axes[1], label='Longitude (¬∞)')\n",
    "    \n",
    "    # Plot 3: Geographic distribution\n",
    "    axes[2].scatter(lon_array.flatten(), lat_array.flatten(), \n",
    "                   c=np.arange(lat_array.size), cmap='viridis', s=30, alpha=0.6)\n",
    "    axes[2].set_title('Geographic Distribution of GCPs', fontweight='bold')\n",
    "    axes[2].set_xlabel('Longitude (¬∞)')\n",
    "    axes[2].set_ylabel('Latitude (¬∞)')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ GCP grid visualization complete\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Cannot visualize - GCP arrays not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "read_sar",
   "metadata": {},
   "source": [
    "## 8. Read and Visualize SAR Data\n",
    "\n",
    "Let's read a subset of the GRD data and visualize the SAR backscatter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "read_sar_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grd_ds:\n",
    "    print(\"Reading SAR data subset...\\n\")\n",
    "    \n",
    "    # Read a subset for visualization (center region)\n",
    "    x_offset = grd_ds.RasterXSize // 4\n",
    "    y_offset = grd_ds.RasterYSize // 4\n",
    "    x_size = grd_ds.RasterXSize // 2\n",
    "    y_size = grd_ds.RasterYSize // 2\n",
    "    \n",
    "    print(f\"Reading subset:\")\n",
    "    print(f\"  Offset: ({x_offset}, {y_offset})\")\n",
    "    print(f\"  Size: {x_size} x {y_size} pixels\")\n",
    "    \n",
    "    # Read data\n",
    "    sar_data = grd_ds.GetRasterBand(1).ReadAsArray(\n",
    "        xoff=x_offset, yoff=y_offset,\n",
    "        win_xsize=x_size, win_ysize=y_size\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Data read successfully\")\n",
    "    print(f\"   Shape: {sar_data.shape}\")\n",
    "    print(f\"   Data type: {sar_data.dtype}\")\n",
    "    print(f\"   Value range: [{sar_data.min()}, {sar_data.max()}]\")\n",
    "    print(f\"   Memory: {sar_data.nbytes / 1024 / 1024:.2f} MB\")\n",
    "    \n",
    "    # Convert to float and apply log scale for visualization\n",
    "    sar_data_float = sar_data.astype(np.float32)\n",
    "    sar_data_float[sar_data_float == 0] = np.nan  # Mask zeros\n",
    "    sar_data_db = 10 * np.log10(sar_data_float + 1)  # Log scale (dB-like)\n",
    "    \n",
    "    print(f\"\\nStatistics (log scale):\")\n",
    "    print(f\"   Min: {np.nanmin(sar_data_db):.2f}\")\n",
    "    print(f\"   Max: {np.nanmax(sar_data_db):.2f}\")\n",
    "    print(f\"   Mean: {np.nanmean(sar_data_db):.2f}\")\n",
    "    print(f\"   Std: {np.nanstd(sar_data_db):.2f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  GRD dataset not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize_sar",
   "metadata": {},
   "source": [
    "## 9. Visualize SAR Backscatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_sar",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sar_data_db' in locals():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    \n",
    "    # Plot 1: SAR backscatter\n",
    "    im1 = axes[0].imshow(sar_data_db, cmap='gray', vmin=np.nanpercentile(sar_data_db, 2),\n",
    "                         vmax=np.nanpercentile(sar_data_db, 98))\n",
    "    axes[0].set_title('Sentinel-1 GRD Backscatter (HH Polarization)\\nLog Scale', \n",
    "                      fontsize=13, fontweight='bold')\n",
    "    axes[0].set_xlabel('Range (pixels)')\n",
    "    axes[0].set_ylabel('Azimuth (pixels)')\n",
    "    cbar1 = plt.colorbar(im1, ax=axes[0], label='Backscatter (dB-like)')\n",
    "    \n",
    "    # Plot 2: Histogram\n",
    "    valid_data = sar_data_db[~np.isnan(sar_data_db)].flatten()\n",
    "    axes[1].hist(valid_data, bins=100, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    axes[1].set_title('Backscatter Distribution', fontsize=13, fontweight='bold')\n",
    "    axes[1].set_xlabel('Backscatter (dB-like)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].axvline(np.nanmean(sar_data_db), color='red', linestyle='--', \n",
    "                   linewidth=2, label=f'Mean: {np.nanmean(sar_data_db):.2f}')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ SAR visualization complete\")\n",
    "    print(\"\\nNote: Bright areas = strong backscatter (urban, rough surfaces, ships)\")\n",
    "    print(\"      Dark areas = weak backscatter (calm water, smooth surfaces)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  SAR data not available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_section",
   "metadata": {},
   "source": [
    "## 10. Summary and Findings\n",
    "\n",
    "### Current Status of Sentinel-1 Support\n",
    "\n",
    "#### ‚úÖ What Works:\n",
    "1. **Dataset Discovery**: Root dataset opens and lists all subdatasets\n",
    "2. **SAR Data Access**: GRD measurement data can be read and visualized\n",
    "3. **GCP Arrays**: Latitude/longitude GCP grids are accessible as subdatasets\n",
    "4. **Basic Metadata**: Product information and array dimensions are available\n",
    "\n",
    "#### ‚ö†Ô∏è Current Limitations:\n",
    "1. **No Automatic GCP Integration**: The driver doesn't automatically attach GCPs from `conditions/gcp/` arrays to the measurement dataset\n",
    "2. **No GEOLOCATION Metadata**: The sparse GCP grid is not exposed via GDAL's GEOLOCATION metadata domain\n",
    "3. **Limited Georeferencing**: Without GCPs, precise georeferencing requires manual interpolation\n",
    "\n",
    "### Sentinel-1 vs Sentinel-3 Geolocation\n",
    "\n",
    "| Aspect | Sentinel-3 OLCI | Sentinel-1 GRD |\n",
    "|--------|----------------|----------------|\n",
    "| **Geolocation Type** | Dense lat/lon arrays | Sparse GCP grid |\n",
    "| **Array Size** | Same as measurement data | Much smaller (23x21 vs 10923x10457) |\n",
    "| **Coverage** | Every pixel | ~1 point per 500 pixels |\n",
    "| **Driver Support** | ‚úÖ Fully automatic | ‚ö†Ô∏è Manual access only |\n",
    "| **GEOLOCATION Metadata** | ‚úÖ Yes | ‚ùå No |\n",
    "\n",
    "### Next Steps for Full Support:\n",
    "\n",
    "To enable automatic georeferencing for Sentinel-1, the driver would need to:\n",
    "1. Detect GCP arrays in `conditions/gcp/` group\n",
    "2. Read the sparse lat/lon grids\n",
    "3. Attach them as GDAL GCPs to the measurement dataset\n",
    "4. Enable reprojection and coordinate transformations\n",
    "\n",
    "### Workarounds:\n",
    "\n",
    "For now, users can:\n",
    "1. Manually read GCP arrays as shown in this notebook\n",
    "2. Interpolate the sparse grid to full resolution if needed\n",
    "3. Use external tools (e.g., SNAP) for full geometric correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup",
   "metadata": {},
   "source": [
    "## 11. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close_datasets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close datasets\n",
    "if 'root_ds' in locals():\n",
    "    root_ds = None\n",
    "if 'grd_ds' in locals():\n",
    "    grd_ds = None\n",
    "if 'lat_ds' in locals():\n",
    "    lat_ds = None\n",
    "if 'lon_ds' in locals():\n",
    "    lon_ds = None\n",
    "\n",
    "print(\"‚úÖ All datasets closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
